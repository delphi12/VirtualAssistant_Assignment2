{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573b1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.linalg import norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab3c3265",
   "metadata": {},
   "source": [
    "Importing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b6b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_01 = pd.read_csv('./DataFiles/train_01.csv')\n",
    "df_dev_01 = pd.read_csv('./DataFiles/dev_01.csv')\n",
    "df_test_01 = pd.read_csv('./DataFiles/test_01.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31f4e9ea",
   "metadata": {},
   "source": [
    "TFid Calculation for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acf3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = []\n",
    "\n",
    "for i in range(0,(len(df_train_01)-1)):\n",
    "    s1 = str(df_train_01['Sent_1'][i])\n",
    "    s2 = str(df_train_01['Sent_2'][i])\n",
    "\n",
    "    # transfer to TF Matrix\n",
    "    cv = TfidfVectorizer(tokenizer=lambda s: s.split())\n",
    "    corpus = [s1, s2]\n",
    "    vectors = cv.fit_transform(corpus).toarray()\n",
    "    # tfidf\n",
    "    tfidf.append(np.dot(vectors[0], vectors[1]) / (norm(vectors[0]) * norm(vectors[1])))\n",
    "\n",
    "# train data for model training\n",
    "#axis=1, add tfidf and Label \n",
    "train_data = pd.concat([df_train_01['Topic_Id'],pd.DataFrame(tfidf),df_train_01['Label']],axis=1)\n",
    "train_data.columns = ['Topic_Id','distance','Label']\n",
    "\n",
    "if(train_data.isna().sum().sum()) > 0:\n",
    "    #drop NaN values\n",
    "    train_data = train_data.dropna()\n",
    "\n",
    "# write the train data to csv file\n",
    "train_data.to_csv(\"./DataFiles/train_data_alg3.csv\",index=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dbed046",
   "metadata": {},
   "source": [
    "TFid Calculation for Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9d1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dev = []\n",
    "\n",
    "for i in range(0,(len(df_dev_01)-1)):\n",
    "    s1 = str(df_dev_01['Sent_1'][i])\n",
    "    s2 = str(df_dev_01['Sent_2'][i])\n",
    "    # transfer to TF Matrix\n",
    "    cv = TfidfVectorizer(tokenizer=lambda s: s.split())\n",
    "    corpus = [s1, s2]\n",
    "    vectors = cv.fit_transform(corpus).toarray()\n",
    "    # tfidf\n",
    "    tfidf_dev.append(np.dot(vectors[0], vectors[1]) / (norm(vectors[0]) * norm(vectors[1])))\n",
    "    #print(tfidf_dev)\n",
    "\n",
    "# dev data for model training\n",
    "#axis=1, add jaccard_dis_dev and Label \n",
    "dev_data = pd.concat([df_dev_01['Topic_Id'],pd.DataFrame(tfidf_dev),df_dev_01['Label']],axis=1)\n",
    "dev_data.columns = ['Topic_Id','distance','Label']\n",
    "\n",
    "if(dev_data.isna().sum().sum()) > 0:\n",
    "    #drop NaN values\n",
    "    dev_data = dev_data.dropna()\n",
    "\n",
    "# write the dev data to csv file\n",
    "dev_data.to_csv(\"./DataFiles/dev_data_alg3.csv\",index=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b43bdc52",
   "metadata": {},
   "source": [
    "TFid Calculation for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d47ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = []\n",
    "\n",
    "for i in range(0,(len(df_test_01)-1)):\n",
    "    s1 = str(df_test_01['Sent_1'][i])\n",
    "    s2 = str(df_test_01['Sent_2'][i])\n",
    "    # transfer to TF Matrix\n",
    "    cv = TfidfVectorizer(tokenizer=lambda s: s.split())\n",
    "    corpus = [s1, s2]\n",
    "    vectors = cv.fit_transform(corpus).toarray()\n",
    "    # tfidf\n",
    "    tfidf_test.append(np.dot(vectors[0], vectors[1]) / (norm(vectors[0]) * norm(vectors[1])))\n",
    "    #print(tfidf_test)\n",
    "\n",
    "# test data for model training\n",
    "#axis=1, add jaccard_dis_test and Label \n",
    "test_data = pd.concat([df_test_01['Topic_Id'],pd.DataFrame(tfidf_test),df_test_01['Label']],axis=1)\n",
    "test_data.columns = ['Topic_Id','distance','Label']\n",
    "\n",
    "if(test_data.isna().sum().sum()) > 0:\n",
    "    #drop NaN values\n",
    "    test_data = test_data.dropna()\n",
    "\n",
    "# write the test data to csv file\n",
    "test_data.to_csv(\"./DataFiles/test_data_alg3.csv\",index=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23eb87b0",
   "metadata": {},
   "source": [
    "Training the model with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b924d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d2f4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data_X, train_data_y\n",
    "train_data_y = train_data['Label']\n",
    "train_data_X = train_data.copy()\n",
    "train_data_X.drop(['Label'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# dev_data_X, dev_data_y\n",
    "dev_data_y = dev_data['Label']\n",
    "dev_data_X = dev_data.copy()\n",
    "dev_data_X.drop(['Label'],axis=1,inplace=True)\n",
    "\n",
    "# test_data_X, test_data_y\n",
    "test_data_y = test_data['Label']\n",
    "test_data_X = test_data.copy()\n",
    "test_data_X.drop(['Label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc81108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " score_tree: 0.6831683168316832\n",
      "\n",
      "\n",
      "f1_score: 0.4810126582278481\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2671\n",
      "           1       0.57      0.41      0.48      1470\n",
      "\n",
      "    accuracy                           0.68      4141\n",
      "   macro avg       0.65      0.62      0.63      4141\n",
      "weighted avg       0.67      0.68      0.67      4141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf_tree = clf_tree.fit(train_data_X,train_data_y)\n",
    "score_tree = clf_tree.score(dev_data_X, dev_data_y)\n",
    "print(\"\\n score_tree:\",score_tree)\n",
    "print(\"\\n\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "dev_y_pred = clf_tree.predict(dev_data_X)\n",
    "dev_y_true = dev_data_y\n",
    "f1 = f1_score(dev_y_true,dev_y_pred)\n",
    "print(\"f1_score:\",f1)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(classification_report(dev_y_true,dev_y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68a657d3",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bc699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " f1_score_test: 0.37500000000000006\n",
      "\n",
      " test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       662\n",
      "           1       0.44      0.33      0.38       175\n",
      "\n",
      "    accuracy                           0.77       837\n",
      "   macro avg       0.64      0.61      0.62       837\n",
      "weighted avg       0.75      0.77      0.76       837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_y_pred = clf_tree.predict(test_data_X)\n",
    "test_y_true = test_data_y\n",
    "f1_test = f1_score(test_y_true,test_y_pred)\n",
    "print(\"\\n f1_score_test:\",f1_test)\n",
    "print(\"\\n test:\")\n",
    "print(classification_report(test_y_true, test_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8a3262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7307413668196088"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(train_data_X, train_data_y)\n",
    "clf.score(dev_data_X, dev_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cc70733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf = clf_rf.fit(train_data_X,train_data_y)\n",
    "score_rf = clf_rf.score(dev_data_X, dev_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa3fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
